name: DevSecOps Pipeline
on:
  push:
    branches: ["main"]
  pull_request:
    branches: ["main"]

jobs:
  build-deploy-scan:
    runs-on: self-hosted
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Cache Python dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}

      - name: Set up Python virtual environment
        run: |
          python3 -m venv venv
          source venv/bin/activate
          pip install --upgrade pip
          rm -rf ~/.cache/pip/*
          pip install -r requirements.txt
          pip install httpx==0.27.2 openai==1.51.0
          checkov --version || pip install checkov==3.2.258
          deactivate

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Bootstrap builder
        run: docker buildx inspect --bootstrap

      - name: Login to GHCR
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ secrets.GHCR_USERNAME }}
          password: ${{ secrets.GHCR_TOKEN }}

      - name: Build & push Docker image
        id: meta
        run: |
          GIT_SHA=$(git rev-parse --short HEAD)
          echo "image_tag=$GIT_SHA" >> $GITHUB_OUTPUT
          docker build -t ${{ secrets.REGISTRY }}/app:$GIT_SHA -t ${{ secrets.REGISTRY }}/app:latest app
          docker push ${{ secrets.REGISTRY }}/app:$GIT_SHA
          docker push ${{ secrets.REGISTRY }}/app:latest
          sed -i "s#\${IMAGE_TAG}#$GIT_SHA#g" app/k8s/deployment.yaml

      - name: Deploy app to k3s
        run: |
          echo "${{ secrets.KUBE_CONFIG }}" | base64 -d > kubeconfig
          chmod 600 kubeconfig
          export KUBECONFIG=kubeconfig
          kubectl apply -f app/k8s/namespace.yaml
          kubectl create secret docker-registry ghcr-secret \
            --docker-server=ghcr.io \
            --docker-username=${{ secrets.GHCR_USERNAME }} \
            --docker-password=${{ secrets.GHCR_TOKEN }} \
            --namespace=app-test \
            --dry-run=client -o yaml | kubectl apply -f -
          kubectl apply -f app/k8s/deployment.yaml
          kubectl apply -f app/k8s/service.yaml
          kubectl apply -f app/k8s/ingress.yaml
          kubectl apply -f app/k8s/networkpolicy.yaml
          kubectl apply -f policies/gatekeeper-templates/deny-high-risk.yaml
          kubectl apply -f policies/gatekeeper-constraints/deny-high-risk.yaml
          sleep 10
          kubectl rollout status -n app-test deploy/demo-app --timeout=600s

      - name: Clear runner cache
        run: |
          rm -rf $HOME/.local/bin/*
          rm -rf $HOME/.cache/*

      - name: Install local scanners
        continue-on-error: true
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          mkdir -p $HOME/.local/bin
          export PATH=$HOME/.local/bin:$PATH
          
          # Install ZAP
          ZAP_VERSION="2.15.0"
          wget https://github.com/zaproxy/zaproxy/releases/download/v$ZAP_VERSION/ZAP_${ZAP_VERSION}_Linux.tar.gz -O zap.tar.gz
          tar -xzf zap.tar.gz -C $HOME/.local/bin
          mv $HOME/.local/bin/ZAP_${ZAP_VERSION} $HOME/.local/bin/zap
          rm -f zap.tar.gz
          
          # Install Trivy
          TRIVY_VERSION="0.66.0"
          curl -L https://github.com/aquasecurity/trivy/releases/download/v$TRIVY_VERSION/trivy_${TRIVY_VERSION}_Linux-64bit.tar.gz -o trivy.tar.gz
          tar -xzf trivy.tar.gz -C $HOME/.local/bin
          chmod +x $HOME/.local/bin/trivy
          trivy --version && echo "Trivy binary is functional" || echo "trivy_docker_fallback=true" >> $GITHUB_ENV
          rm -f trivy.tar.gz
          
          # Install Syft
          curl -sSfL https://raw.githubusercontent.com/anchore/syft/main/install.sh | sh -s -- -b $HOME/.local/bin
          echo "$HOME/.local/bin" >> $GITHUB_PATH

      - name: Verify scanner installation
        continue-on-error: true
        run: |
          export PATH=$HOME/.local/bin:$PATH
          source venv/bin/activate
          semgrep --version || { echo "Semgrep installation failed"; exit 1; }
          checkov --version || { echo "Checkov installation failed"; exit 1; }
          $HOME/.local/bin/zap/zap.sh -version || { echo "OWASP ZAP installation failed"; exit 1; }
          deactivate
          if [ "${{ env.trivy_docker_fallback }}" != "true" ]; then
            trivy --version || echo "trivy_docker_fallback=true" >> $GITHUB_ENV
          fi
          syft --version || { echo "Syft installation failed"; exit 1; }
          conftest --version || true
          gitleaks version || { echo "Gitleaks installation failed"; exit 1; }

      - name: Run SAST scan
        continue-on-error: true
        run: |
          export PATH=$HOME/.local/bin:$PATH
          source venv/bin/activate
          semgrep --config scanners/semgrep_rules.yml --json > sast.json || echo "[]" > sast.json
          deactivate

      - name: Run Secrets scan
        continue-on-error: true
        run: |
          export PATH=$HOME/.local/bin:$PATH
          gitleaks detect --source . --report-path secrets.json || echo "[]" > secrets.json

      - name: Run IaC scan
        continue-on-error: true
        run: |
          export PATH=$HOME/.local/bin:$PATH
          source venv/bin/activate
          mkdir -p scanners
          if [ ! -f scanners/checkov.yml ]; then
            printf '{"results": {"failed_checks": [], "passed_checks": [], "skipped_checks": []}}' > scanners
            deactivate
            exit 0
          fi
          checkov -d app/k8s --config-file scanners/checkov.yml --output json --output-file-path scanners 2> checkov_error.log || \
            printf '{"results": {"failed_checks": [], "passed_checks": [], "skipped_checks": []}}' > scanners
          deactivate

      - name: Run SCA scan
        continue-on-error: true
        run: |
          export PATH=$HOME/.local/bin:$PATH
          if [ "${{ env.trivy_docker_fallback }}" != "true" ]; then
            trivy fs --format json --output sca.json . || echo "[]" > sca.json
          else
            docker run --rm -v $(pwd):/workspace -w /workspace aquasec/trivy:0.66.0 fs --format json --output sca.json . || echo "[]" > sca.json
          fi

      - name: Generate SBOM
        continue-on-error: true
        run: |
          export PATH=$HOME/.local/bin:$PATH
          syft dir:app -o json > sbom.json || echo "[]" > sbom.json

      - name: Wait for service to be ready
        continue-on-error: true
        run: |
          export KUBECONFIG=kubeconfig
          kubectl wait --for=condition=ready pod -n app-test -l app=demo-app --timeout=300s
          kubectl get service demo-app-svc -n app-test
          kubectl get ingress -n app-test
          kubectl describe ingress demo-app-ing -n app-test

      - name: Test internal connectivity
        run: |
          export KUBECONFIG=kubeconfig
          SERVICE_IP=$(kubectl get service demo-app-svc -n app-test -o jsonpath="{.spec.clusterIP}")
          echo "Service IP: $SERVICE_IP"
          kubectl get pods -n app-test -l app=demo-app -o wide
          kubectl describe service demo-app-svc -n app-test
          kubectl get endpoints demo-app-svc -n app-test -o wide
          kubectl run test-connectivity --image=curlimages/curl:latest --rm -i --restart=Never -n app-test -- sh -c "\
            echo \"Testing service IP: $SERVICE_IP:80\"; \
            curl -v --fail --connect-timeout 10 --max-time 30 \"http://$SERVICE_IP:80\" || echo \"Service IP failed\"; \
            echo \"Testing service DNS:\"; \
            curl -v --fail --connect-timeout 10 --max-time 30 \"http://demo-app-svc.app-test.svc.cluster.local:80\" || echo \"Service DNS failed\"; \
          " || echo "Connectivity test failed"

      - name: Run ZAP scan
        run: |
          export KUBECONFIG=kubeconfig
          mkdir -p scanners
          TARGET_URL="http://staging.hamza-builds.info/"
          echo "$TARGET_URL" > scanners/target-url

          # Set ZAP options (JSON + HTML report + config file)
          echo "-J /zap/wrk/zap-report.json -r /zap/wrk/zap-report.html --active-scan true" > scanners/zap-options

          # Apply ConfigMap
          kubectl create configmap zap-config \
            --from-file=target-url=scanners/target-url \
            --from-file=zap-options=scanners/zap-options \
            -n app-test --dry-run=client -o yaml | kubectl apply -f -

          kubectl delete job zap-scan -n app-test --ignore-not-found=true
          kubectl apply -f scanners/zap-job.yaml

          kubectl wait --for=condition=complete job/zap-scan -n app-test --timeout=1800s || {
            echo "ZAP scan failed or timed out"
            kubectl describe job zap-scan -n app-test
            kubectl logs -n app-test -l job-name=zap-scan --tail=100
          }


          POD_NAME=$(kubectl get pod -n app-test -l job-name=zap-scan -o jsonpath="{.items[0].metadata.name}")
          kubectl cp app-test/$POD_NAME:/zap/wrk/zap-report.json zap-report.json || echo "{}" > zap-report.json
          kubectl cp app-test/$POD_NAME:/zap/wrk/zap-report.html zap-report.html || echo "<html><body>No report</body></html>" > zap-report.html

      - name: Merge findings
        run: |
          source venv/bin/activate
          python3 risk_model/inference/merge_findings.py \
            --sast sast.json \
            --secrets secrets.json \
            --iac scanners/results.json \
            --sca sca.json \
            --dast zap-report.json \
            --out findings.jsonl
          deactivate

      - name: AI inference + HTML report
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        run: |
          source venv/bin/activate
          python3 risk_model/inference/infer.py \
            --artifacts-dir artifacts \
            --in findings.jsonl \
            --out enriched.jsonl \
            --report report.html
          deactivate

      - name: Evaluate adaptive gate
        id: gate
        run: |
          source venv/bin/activate
          python3 adaptive/evaluate_gate.py > gate.json
          THRESHOLD=$(jq -r .adaptive_threshold gate.json)
          echo "threshold=$THRESHOLD" >> $GITHUB_OUTPUT
          deactivate

      - name: Check gate
        env:
          THRESH: ${{ steps.gate.outputs.threshold }}
        run: |
          source venv/bin/activate
          python3 adaptive/check_gate.py
          deactivate

      - name: Run Red Team tests
        continue-on-error: true
        run: |
          export KUBECONFIG=kubeconfig
          source venv/bin/activate
          TARGET_HOST=$(kubectl get ingress -n app-test -o jsonpath=".items[0].status.loadBalancer.ingress[0].hostname" 2>/dev/null || echo "staging.hamza-builds.info")
          python3 redteam/run_attacks.py --target "http://$TARGET_HOST:80" --out redteam_results.json || echo "[]" > redteam_results.json
          deactivate

      - name: Debug app connectivity
        if: always()
        run: |
          export KUBECONFIG=kubeconfig
          POD_NAME=$(kubectl get pods -n app-test -l app=demo-app -o jsonpath=".items[0].metadata.name")
          if [ ! -z "$POD_NAME" ]; then
            kubectl logs -n app-test $POD_NAME --tail=200
            kubectl describe pod -n app-test $POD_NAME
            kubectl exec -n app-test $POD_NAME -- sh -c "apk add --no-cache curl net-tools || apt-get update && apt-get install -y curl net-tools"
            kubectl exec -n app-test $POD_NAME -- netstat -tulnp
            SERVICE_IP_INTERNAL=$(kubectl get service demo-app-svc -n app-test -o jsonpath=".spec.clusterIP")
            kubectl exec -n app-test $POD_NAME -- curl -v --fail --connect-timeout 5 --max-time 10 http://127.0.0.1:8080
            kubectl exec -n app-test $POD_NAME -- curl -v --fail --connect-timeout 5 --max-time 10 http://$SERVICE_IP_INTERNAL:80
          fi
          kubectl describe deployment -n app-test demo-app

      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: security-report-${{ github.run_number }}
          path: |
            report.html
            findings.jsonl
            enriched.jsonl
            redteam_results.json
            zap-report.json
            zap-report.html
            scanners/results.json
            sast.json
            secrets.json
            sca.json
            sbom.json
            gate.json

      - name: Clean up kubeconfig
        if: always()
        run: rm -f kubeconfig
